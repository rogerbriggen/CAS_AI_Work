{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1fTy0cTQC3Wj1gURAsoHmyDAEy_vqWnqC","timestamp":1742308135043},{"file_id":"15UQVtovPVQp34Eu6yOmCFWfA3aURFpnh","timestamp":1742303466233},{"file_id":"1HAvIASM5hNQe-vqTE5dn0YFUA8fIFeHF","timestamp":1742302922013},{"file_id":"1sWJ6YdDIA_qYz2gP6jkBb5-P9nZ9C58H","timestamp":1741074319540},{"file_id":"17b2xTtIoErmyvv9Nq-wXHWd5YUWaOLei","timestamp":1741042986285},{"file_id":"13S1XqujQb_510jIZtlGuNJQIuHFKY3Cc","timestamp":1741031812351},{"file_id":"1w4p6q7r7nkLoiREGEWS1Q3j2FH_rhk8j","timestamp":1711408526825},{"file_id":"17hDYTaaNNmwgGEhOlzHqzH9SqREpxx91","timestamp":1711352680764}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Eigene Probe-Klausur - ertsellt von 3 Teams **100 Punkte**\n","\n","---\n","\n","\n","\n","---\n","\n"],"metadata":{"id":"RyFprCKICO34"}},{"cell_type":"markdown","source":["## 1 - Team 1 - Dense Network Params **50 Punkte**\n","\n","\n","---\n","\n","\n","\n"],"metadata":{"id":"QL3vXpgJCWBg"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"9rhep4xNXVYt"},"outputs":[],"source":["import torch\n","import numpy as np\n","from torch import nn\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from torch.utils.data import TensorDataset, DataLoader, Dataset\n","from sklearn.metrics import accuracy_score\n"]},{"cell_type":"code","source":["# Matrizenarithmetik\n","# Vervollständige die fehlenden Werte\n","# a)\n","x_1 = #\n","x_2 = #\n","\n","a = torch.randn(x_1, 3)\n","b = torch.randn(4, x_2)\n","c = a + b\n","assert c.size() == (4,3)\n","\n","x_3 = #\n","x_4 = #\n","\n","b = c - a\n","assert b.size() == (x_3, x_4)\n","\n","# b)\n","x_5 = #\n","x_6 = #\n","\n","a = torch.randn(5, 4)\n","b = torch.randn(x_5, 4)\n","c = a * b\n","assert c.size() == (x_6, 4)\n","\n"],"metadata":{"id":"3dzCwCwnX96z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Lösung\n"],"metadata":{"id":"vnNVZnx0sBVV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialisierung des Vektors v und der Matrix M\n","v = torch.randn(3, dtype=torch.float)\n","M = torch.randn(3, 2, dtype=torch.float)\n","b = torch.randn(2, dtype=torch.float)\n","\n","#Berechne das Produkt der transponierten Matrix M.T und des Vektors v.\n","y = _____ -> #torch.matmul(M.T, v)  # M.T ist die Transponierte von M, um das Matrix-Vektor-Produkt zu berechnen\n","\n","#Addiere den bias-Vektor b zum Ergebis des Matrix-Vektor Produkts\n","y_with_bias = _____# y + b  # bias\n","# Ausgabe der Ergebnisse\n","print(\"Matrix-Vektor-Produkt:\\n\", y)\n","print(\"Matrix-Vektor-Produkt mit Bias:\\n\", y_with_bias)"],"metadata":{"id":"jT-bUto-YA8l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Gib einen sinnvollen und erlaubten Wert bei \"xxxx\" ein und erkläre, wie der Wert das Resultat beinflusst.\n","\n","class DQN(nn.Module):\n","    def __init__(self, n_observations, n_actions):\n","        super(DQN, self).__init__()\n","        self.layer1 = nn.Linear(n_observations, 128)\n","        self.layer2 = nn.Linear(128, 512)\n","        self.layer3 = NoisyLinear(512, n_actions, sigma_init=xxxx) #code hier\n","\n","    def forward(self, x):\n","        x = F.relu(self.layer1(x))\n","        x = F.relu(self.layer2(x))\n","        return self.layer3(x)\n"],"metadata":{"id":"bKve_8TdYD8Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Aufgabe\n","# i) Vervollständigen sie die fehlenden Werte\n","# ii) Berechnen sie die Anzahl trainable Parameter\n","\n","data = torch.rand((1000, 6))\n","\n","var = # hier code\n","\n","class FCN(nn.Module):\n","  def __init__(self):\n","    super(FCN, self).__init__()\n","    self.net = nn.Sequential(\n","        nn.LazyLinear(out_features=var), ##\n","        nn.ReLU(),\n","        nn.Linear(in_features=8, out_features=16, bias=False),\n","        nn.ReLU()\n","    )\n","\n","  def forward(self, x):\n","    return self.net(x)\n","\n","model = FCN()\n","model.forward(data)\n","\n"],"metadata":{"id":"HaSFJG1yYF76"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","class CustomNetwork(nn.Module):\n","    def __init__(self, input_dim, output_dim, dropout_prob=0.3):\n","        super().__init__()\n","\n","        # Define layers\n","        self.fc1 = nn.Linear(...)  # Define the parameter(s)\n","        self.bn1 = nn.BatchNorm1d(...)  # Define the parameter(s)\n","        self.dropout1 = nn.Dropout(dropout_prob)\n","\n","        self.fc2 = nn.Linear(...)  # Define the parameter(s)\n","        self.bn2 = nn.BatchNorm1d(...)  # Define the parameter(s)\n","        self.dropout2 = nn.Dropout(dropout_prob)\n","\n","        self.fc3 = nn.Linear(...)  # Define the parameter(s)\n","        self.activation = nn.ReLU()\n","\n","    def forward(self, x):\n","        x = self.activation(self.bn1(self.fc1(x)))\n","        x = self.dropout1(x)\n","        x = self.activation(self.bn2(self.fc2(x)))\n","        x = self.dropout2(x)\n","        return self.fc3(x)\n","\n","# Example usage:\n","input_dim = 256  # Example input size\n","output_dim = 3  # Example output size\n","\n","# TODO: Instantiate the network with the correct layer sizes\n","model = CustomNetwork(input_dim, output_dim)\n","\n","# Print model summary\n","print(model)"],"metadata":{"id":"pbNu5nxuYZgf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Wir definieren folgende **trainierbare Netzwerkparameter**:"],"metadata":{"id":"Nd7kEl34J8Nr"}},{"cell_type":"markdown","source":["### 2 - Team 2 Vervollständigen Sie bitte den Code und bestimmen Sie: **18 Punkte**\n","\n","1. Vervollständigen Sie bitte den Code an den **fünf (5)** Stellen: missing 1, 2, 3, 4, 5 - **10 Punkte**\n","> Beachten Sie dabei, dass:\n","> - Zuerst werden die Conv. Layer durchlaufen, anschliessend die Linearen Layer\n","> - Die Datensatz-Länge ist frei wählbar (jedoch nicht die Anzahl der Spalten/Variablen)\n","2. Nachdem Sie fehlende Grössen eingefügt haben, können Sie jetzt die Anzahl der trainable Parameter pro Layer bestimmen - **8 Punkte**\n","\n"],"metadata":{"id":"Y04-Wmx1Rjci"}},{"cell_type":"markdown","source":["Gegeben sind 4 Images **unterscheidlicher Grösse**\n","\n"],"metadata":{"id":"Ap7ecUb_SpX-"}},{"cell_type":"code","source":["class NeuronalNet(nn.Module):\n","    def __init__(self) -> None:\n","        super(NeuronalNet, self).__init__()\n","\n","        # 3 channel input, 6 channel output, size of 5x5x tiles => will result in shape 28x28 shape\n","        self.conv1 = nn.Conv2d(\"input value here\", \"input value here\", 5)\n","\n","        # 2 x 2 tiles with Stride of 2 will result in shape 14 x 14\n","        self.pool = nn.MaxPool2d(2, 2)\n","\n","        # 6 channel input, 16 channel output, size of 5x5x tiles => will result in shape 10x10 shape\n","        self.conv2 = nn.Conv2d(6, \"input value here\", 5)\n","\n","        self.fc1 = nn.Linear(25, 120)\n","        self.fc2 = nn.Linear(\"input value here\", 84)\n","        self.fc3 = nn.Linear(\"input value here\", 10)\n","\n","\n","    def forward(self, x):\n","        logits = self.pool(F.relu(self.conv1(x)))\n","        logits = self.pool(F.relu(self.conv2(logits)))\n","\n","        logits = torch.flatten(logits, 1) # flatten all dimensions except batch\n","        logits = F.relu(self.fc1(logits))\n","        logits = F.relu(self.fc2(logits))\n","        logits = self.fc3(logits)\n","        return logits\n","\n","net = NeuronalNet()"],"metadata":{"id":"IdWjs81mu9GV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Image = torch.rand((3, 32, 32))\n","Image"],"metadata":{"id":"RSI9NKozp6ZY","executionInfo":{"status":"error","timestamp":1742308095849,"user_tz":-60,"elapsed":32,"user":{"displayName":"cliffi30","userId":"06609746833928087856"}},"outputId":"e7522990-a805-4243-f8ca-fd83638e9110","colab":{"base_uri":"https://localhost:8080/","height":159}},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'torch' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-3cb297aa35dd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mImage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"]}]},{"cell_type":"code","source":["logits = net(Image)\n","logits.shape"],"metadata":{"id":"Mzc3pjMwZgmj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["logits"],"metadata":{"id":"WjO8n9VoaYhx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 1.2 Sie wollen ein **Dense-Network** erstellen, das auf solchen unterschiedlich grossen Bildern trainiert werden kann **12 Punkte**\n","1. Ergänzen Sie die fehlenden Code-Zeilen **10 Punkte**\n","2. Bestimmen Sie das Output-Shape des Netzwerks **2 Punkte** -> Network Output shape:  {torch.Size([1, 10])}"],"metadata":{"id":"IXoLhuHO0DtE"}},{"cell_type":"markdown","source":["## 3 - Team 3 Deep Reinforcement Learning - Fehler Suche **50 Punkte**\n","\n","**Aufgabenstellung**: Fehler in der Rock-Paper-Scissors-Environment finden und beheben.\n","Diese Vorlage enthält eine fehlerhafte Implementierung einer Rock-Paper-Scissors-Umgebung für ein Deep Reinforcement Learning (DRL)-Modell mit TorchRL.\n","Eure Aufgabe ist es, die Fehler zu finden und zu beheben, damit das Modell korrekt funktioniert.\n","\n","---\n","\n"],"metadata":{"id":"FaeRT9ptngE6"}},{"cell_type":"code","source":["!pip install --upgrade torchrl"],"metadata":{"id":"bMPCXGHno8Kd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Imports\n","from typing import Optional\n","\n","import pandas as pd\n","import numpy as np\n","\n","import torch\n","from torch.optim import Adam\n","\n","from tensordict import TensorDict, TensorDictBase\n","from tensordict.nn import TensorDictModule, TensorDictSequential\n","\n","from torchrl.modules import EGreedyModule, MLP, QValueModule\n","from torchrl.data import OneHot, Composite, UnboundedContinuous, Categorical, Unbounded\n","from torchrl.collectors import SyncDataCollector\n","from torchrl.objectives import DQNLoss, SoftUpdate\n","from torchrl.envs import EnvBase, StepCounter, TransformedEnv, step_mdp\n","from torchrl.envs.utils import check_env_specs\n","from torchrl.data.replay_buffers import ReplayBuffer\n","from torchrl.data.replay_buffers.storages import LazyTensorStorage"],"metadata":{"id":"J4bRxZEXpEZz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Aktionen und Rewards definieren\n","ACTIONS = {0: \"Schere\", 1: \"Stein\", 2: \"Papier\"}\n","REWARDS = {\n","    (0, 0): 0, (0, 1): -1, (0, 2): 1,\n","    (1, 0): 1, (1, 1): 0, (1, 2): -1,\n","    (2, 0): -1, (2, 1): 1, (2, 2): 0\n","}\n","RANDOM = np.random.default_rng(42)\n","def generate_random_moves(num_samples=1000):\n","    data = {\n","        # Unser Gegner hat leichten Hang zur Schere ;-)\n","        \"move\": RANDOM.choice([0, 1, 2], size=num_samples, p=[0.4, 0.3, 0.3])\n","    }\n","    return pd.DataFrame(data)\n","\n","class RockPaperScissorsEnv(EnvBase):\n","    def __init__(self, device=\"cpu\"):\n","        super().__init__(device=device)\n","        self.dataset = generate_random_moves()\n","        self.num_features = 1\n","        self.observation_spec = Composite(observation=Unbounded(shape=(1,), dtype=torch.float32))\n","        self.action_spec = Composite(action=OneHot(n=len(ACTIONS.items()), dtype=torch.int64))\n","        self.reward_spec = Composite(reward=Unbounded(shape=(1,), dtype=torch.float32))\n","\n","    def _step(self,tensordict):\n","        action = tensordict[\"action\"].argmax(dim=-1).item()\n","        next_sample = self.dataset.sample(1).iloc[0]\n","        next_state = torch.tensor(\n","            next_sample[\"move\"].astype(np.float32),\n","            dtype=torch.float32\n","        )\n","        opponent_action = torch.randint(0, 3, (1,)).item()  # Zufälliger Gegner\n","        reward = REWARDS[(action, next_sample[\"move\"].astype(np.float32))]\n","        return TensorDict({\n","            \"observation\": next_state,\n","            \"success\": torch.tensor([reward], dtype=torch.float32),\n","            \"done\": torch.tensor([False], dtype=torch.bool),\n","            \"action_value\": action\n","      })\n","\n","    def _reset(self, tensordict=None):\n","        sample = self.dataset.sample(1).iloc[0]\n","        print(f\"Sample {sample}\")\n","        # Get the value from the 'move' column of the first row\n","        state = torch.tensor(sample[\"move\"], dtype=torch.float32)\n","\n","        return TensorDict({\n","            \"observation\": torch.tensor([state], dtype=torch.float32),\n","            \"done\": torch.tensor([False], dtype=torch.bool),  # Explicit shape [1]\n","        }, batch_size=[])\n","\n","\n","    def _set_seed(self, seed: Optional[int]):\n","        pass"],"metadata":{"id":"lnC3BPyDpImp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["env = RockPaperScissorsEnv()\n","\n","value_mlp = MLP(in_features=env.num_features, out_features=env.action_spec.shape[-1], num_cells=[64, 64])\n","value_net = TensorDictModule(value_mlp, in_keys=[\"observation\"], out_keys=[\"action_value\"])\n","policy = TensorDictSequential(value_net, QValueModule(spec=env.action_spec))\n","exploration_module = EGreedyModule(\n","    env.action_spec, annealing_num_steps=10_000, eps_init=0.9\n",")\n","policy_explore = TensorDictSequential(policy, exploration_module)"],"metadata":{"id":"dajZAtB-pLjG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_env():\n","  return TransformedEnv(RockPaperScissorsEnv(), StepCounter(max_steps=1_000))"],"metadata":{"id":"KP3LpOpEpOss"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["init_rand_steps = 500\n","collector = SyncDataCollector(\n","    create_env_fn = create_env,\n","    policy = policy_explore,\n","    frames_per_batch=1,  # ✅ Match the batch size\n","    total_frames=1_000,\n","    init_random_frames=init_rand_steps,\n","    storing_device=\"cpu\",  # ✅ Ensure storing happens on CPU\n","    split_trajs=False,  # ✅ Prevent trajectory splitting from dropping keys\n","    exploration_type=\"mode\"\n",")\n","rb = ReplayBuffer(storage=LazyTensorStorage(100_000))\n","loss = DQNLoss(value_network=policy, action_space=env.action_spec, delay_value=True)\n","optim = Adam(loss.parameters(), lr=0.02)\n","updater = SoftUpdate(loss, eps=0.99)"],"metadata":{"id":"KyOnUUfZpSQT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","total_count = 0\n","total_episodes = 0\n","optim_steps = 1\n","t0 = time.time()\n","for i, data in enumerate(collector):\n","    # Write data in replay buffer\n","    #print(data)\n","    rb.extend(data)\n","    max_length = rb[:][\"next\", \"step_count\"].max()\n","    #print(\"max_length\", max_length)\n","    if len(rb) > init_rand_steps:\n","        # Optim loop (we do several optim steps\n","        # per batch collected for efficiency)\n","        for _ in range(optim_steps):\n","            sample = rb.sample(100)\n","            loss_vals = loss(sample)\n","            #print(\"loss function is called:\", loss_vals)\n","            loss_vals[\"loss\"].backward()\n","            optim.step()\n","            optim.zero_grad()\n","            # Update exploration factor\n","            exploration_module.step(data.numel())\n","            # Update target params\n","            updater.step()\n","            #if i % 10:\n","            #    print(f\"Max num steps: {max_length}, rb length {len(rb)}\")\n","            total_count += data.numel()\n","            total_episodes += data[\"next\", \"done\"].sum()\n","        #if max_length > 200:\n","        #    break\n","\n","t1 = time.time()\n","\n","print(\n","    f\"solved after {total_count} steps, {total_episodes} episodes and in {t1-t0}s.\"\n",")"],"metadata":{"id":"P3EecZlopViN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Good Luck!\")"],"metadata":{"id":"mLJ3O-QG5SnN"},"execution_count":null,"outputs":[]}]}